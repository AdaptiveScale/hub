{
  "parents": [
    "system:cdap-data-pipeline[4.0.0,10.0.0-SNAPSHOT)",
    "system:cdap-data-streams[4.0.0,10.0.0-SNAPSHOT)",
    "system:cdap-etl-batch[4.0.0,10.0.0-SNAPSHOT)",
    "system:cdap-etl-realtime[4.0.0,10.0.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.Wrangler-transform": "{\"metadata\":{\"spec-version\":\"1.0\"},\"configuration-groups\":[{\"label\":\"Wrangler\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Name of the field ('*' to transform all fields)\",\"name\":\"field\",\"widget-attributes\":{\"default\":\"*\"}},{\"widget-type\":\"textarea\",\"label\":\"Transformation Directives\",\"name\":\"directives\"},{\"widget-type\":\"textbox\",\"label\":\"Max number of errored events before stopping pipeline\",\"name\":\"threshold\",\"widget-attributes\":{\"default\":\"5\"}}]}],\"outputs\":[{\"name\":\"schema\",\"label\":\"schema\",\"widget-type\":\"schema\",\"widget-attributes\":{\"schema-types\":[\"boolean\",\"int\",\"long\",\"float\",\"double\",\"bytes\",\"string\"],\"schema-default-type\":\"string\",\"property-watch\":\"format\"}}]}",
    "doc.Wrangler-transform": "# Wrangler Transform\n\nA plugin for performing data transformation based on directives. The directives are generated either by an interactive user interface or manual entered into the plugin.\n\n## Directives\nWrangler plugin supports an easy way to specify data transformation using directives. Directives are\ninstructions that tell plugin how to transform the incoming record. All of the directives are transformational\nand they operate on the input row to generate a new row. The directives are applied on the input record in\nthe order they are specified.\n\n## Types of Directives\nFollowing are different types of directives that are supported by the Wrangler plugin.\n\n### Parsers\n\n#### CSV Parser\n\nParses a column a comma separated value (CSV).\n\n**Specification**\n```\n  parse-as-csv {column-name} {delimiter} {true or false to indicate skip empty lines}\n```\n* column-name - Name of the column to parsed as CSV\n* delimiter - Specifies the delimiter to be used for parsing as CSV record.\n* Skip empty lines - true, if you want to skip empty lines, false otherwise (default: false)\n\n**Example**\n```\n  parse-as-csv body , true,\n  drop body,\n  rename body_col1 date,\n  parse-as-csv date / true,\n  rename date_col1 month,\n  rename date_col2 day,\n  rename date_col3 year\n```\n\n#### JSON Parser\n\nParses a column as a JSON.\n\n**Specification**\n```\n  parse-as-json {column-name}\n```\n\n**Example**\n```\n  parse-as-json body,\n  parse-as-json body.deviceReference,\n  parse-as-json body.deviceReference.OS,\n  parse-as-csv  body.deviceReference.screenSize | true,\n  drop body.deviceReference.screenSize,\n  rename body.deviceReference.screenSize_col1 size1,\n  rename body.deviceReference.screenSize_col2 size2,\n  rename body.deviceReference.screenSize_col3 size3,\n  rename body.deviceReference.screenSize_col4 size4,\n  json-path body.deviceReference.alerts signal_lost $.[*].['Signal lost'],\n  json-path signal_lost signal_lost $.[0],\n  drop body,\n  drop body.deviceReference.OS,\n  drop body.deviceReference,\n  rename body.deviceReference.timestamp timestamp,\n  set column timestamp timestamp / 1000000,\n  drop body.deviceReference.alerts,\n  set columns timestamp,alerts,phone,battery,brand,type,comments,deviceId,os_name,os_version,size1,size2,size3,size4,signal\n```\n\n#### Fixed Length Parser\n\nParses a column as fixed length record with range specifications specified.\n\n**Specification**\n```\n  parse-as-fixed-length {column-name} s1-e1[[,[s2]*],[s3-e3]*]*\n```\n\n**Example**\n```\n  parse-as-fixed-length body 1-2,3-4,5,6-9\n```\n\n#### (Deprecated) set format\nThis directive specifies how the input needs to be parsed. Currently Wrangler supports parsing of CSV feed.\nThe input is parsed as CSV with delimiter specified.\n\n**Specification**\n```\n  set format {type} {delimiter} {configuration}\n```\n* type - Currently the only type supported is CSV.\n* delimiter - When type is CSV, the delimiter to be used for splitting into columns. If you would like to specify a\ndelimiter like a tab, then you specify it as '\\\\t'.\n* configuration - Specifies configuration based on type, for CSV, ability to skip empty lines is specifiable.\nThe value can be either 'true' or 'false'.\n\n**Example**\n```\n  set format csv , false\n```\n\n### Sed\nA stream editor directive that can be used for performing basic text operations on the\ncolumn string to which it is applied.\n\n**Specification**\n```\n  sed <column-name> <sed-script>\n```\n\n* column-name Specifies the name of the column on which the sed script is applied.\n* sed-script Specifies the sed script to be applied to the column.\n\n**Example**\n```\n  sed body s/\"//g\n```\n\n### Changing Case\n\nDirective that provides the ability to change the case of a column value. One can change the column value\n to uppercase, lowercase or titlecase.\n\n**Specification**\n```\n uppercase {column-name}\n lowercase {column-name}\n titlecase {column-name}\n```\n* column-name - Specifies the name of the column to which the changing case directives are applied.\n\n**Example**\n```\n  uppercase state\n  lowercase email\n  titlecase name\n```\n### Drop a column\n\nDrop a column directive will remove a column from the input record. The resulting output record will not\ninclude the column specified in the directive.\n\n**Specification**\n```\n  drop {column-name}\n```\n\n* column-name - name of the column to be dropped. If the column name doesn't exist, the processing is stopped.\n\n**Example**\n```\n  drop zipcode\n```\n\n### Rename a column\n\nRenames the name of the column.\n\n**Specification**\n```\n  rename {source-column-name} {destination-column-name}\n```\n* source-column-name - Name of the column to be renamed. If the column name doesn't exist, the processing is stopped.\n* destination-column-name - Name of the column to be set to.\n\n**Example**\n```\n  rename email emailid\n```\n### Splitting Column\n\nOften times there is need to split a column based on fixed indexes or based on a delimiter. The Wrangler\nplugin support two ways to split a string.\n\n* Based on start and end index &\n* Based on delimiter\n\nIndex based split will take a source input column value and extract substring from start index to end index into\n a destination column name. This is mainly used for extracting substring from a source string.\n\n```\n  indexsplit {source-column-name} {start} {end} {destination-column-name}\n```\n**Specification**\n* source-column-name - Name of the source column that needs to be split\n* start - Start index to split. If start is less than 0, then it's defaulted to 0.\n* end - End index to split. If end is greater than length of source-column-name value, it's defaulted to it's length.\n* destination-column-name - Name of the column into which the value between start,end value from\nsource-column-name is stored.\n\n**Example**\n```\n  indexsplit ssn 7 11 last4ssn\n```\n\nDelimiter based splitter would split the source column value based on delimiter into two columns.\nFirst column will include the value to the left of the delimiter (excluding delimiter) and the\nsecond column will hold the value to the right of the delimiter.\n\n```\n  split {source-column-name} {delimiter} {new-column-1} {new-column-2}\n```\n**Specification**\n* source-column-name - Name of the source column that needs to be split\n* delimiter - Delimiter to be used to split the source-column-name\n* new-column-1 - Name of the new column that contains the substring left of delimiter. If the column doesn't\nexist then it will be added. If it exists, it will replace.\n* new-column-2 - Name of the new column that contains the substring right of delimiter. If the column doesn't\nexist then it will be added. If it exists, it will replace.\n\n**Example**\n```\n  split email @ name domain\n```\n\n### Specify column names\n\nThis directive specifies the name of the columns. After this directive is specified, the following\ndirectives should use the new names of the columns specified by this directive.\n\n**Specification**\n```\n  set columns {column-name-1},{column-name-2}, ... {column-name-3}\n```\n* {column-name-x} Specifies a list of column names to be assigned to column.\n\n**Example**\n```\n  set columns id,fname,lname,email,address,city,state,zip\n```\n\n### Filter Row\n\nDirective for filtering rows either based on a condition or based on regular expression. Upon execution of\nthis directive, the following directives would be excluded of the rows that were filtered by this directive.\n\nCondition based filtering allows one to specify an expression that if results in 'true' would filter the row else\nwould pass the row as-is to the next directive.\n\n\n**Specification**\n```\n  filter-row-if-true {condition}\n```\n\n* condition - A JEXL expression.\n\n**Example**\n```\n  set columns id,fname,lname,email,address,city,state,zip\n  filter-row-if-true id > 200\n```\n\nRegular expression based filtering applies an regular expression on the value of a column specified in the\ndirective. If the {condition} is true, the row will be skipped else it will be passed down to next step.\n```\n  filter-row-if-matched {column-name} {regex}\n```\n\n**Specification**\n* column-name - Name of the column on which regex is applied. The regex is actually applied on the value of the column.\n* regex - Standard regular expression.\n\n**Example**\n```\n  set columns id,fname,lname,email,address,city,state,zip\n  filter-row-if-matched email .*@joltie.io\n```\n\n### Set Column with expression\nSet column directive allows you assign the result of a expression specified in JEXL format to a column.\nJEXL implements an Expression Language for expressing not so complex expressions. Syntax support JEXL are\navailable [here](http://commons.apache.org/proper/commons-jexl/reference/syntax.html).\n\n**Specification**\n```\n  set column {column-name} {expression}\n```\n\n* column-name - Name of the column to which the result of expression is saved to.\n* expression - Expression to be evaluated specified in Jexl syntax.\n\n**Example**\n```\n  set column salary hrlywage * 160\n  set column hrlywage Math:abs(toDouble(hrlywage))\n```\n\n## Quantize\nThis directive quantizes a continous value of a column through a range table\nspecified. The quantization ranges are all real numbers, with low specifying the low end of the\n range and high specifying the high end of the range. Associated with the range is the\n value that if the incoming value falls in the range it would be assigned that value.\n The range is a closed range - [low:high] = {x | low <= x <= high}. Also, the high endpoint\n should be greater than low endpoint.\n\n**Specification**\n```\n  quantize {source-column} {destination-column} {quantization-table}\n```\n\n* source-column : Name of the column which has to be quantized\n* destination-column : Name of the column to which the quantized value should be added.\n* quantization-table : Specifies the quantization table in the following format low:high=value[,low:high=value]*\nthe range specified in the quantization table is a closed range  and all the ranges specified are mutually exclusive.\n\n**Example**\n```\n  quantize hrlywage wagecategory 0.0:4.99=LOW,5.0:13.99=NORMAL,14.0:29.99=HIGH,30.0:100.0=VERY HIGH\n```\n\n### Mask Column\nData masking (also known as data scrambling and data anonymization) is the process of replacing sensitive\ninformation with realistic, but scrubbed, data based on masking rules. This plugin supports two types of\n masking method\n\n* Substitution based &\n* Shuffle based\n\nSubstitution based masking allows you to mask data based on a masking pattern. The patterns are specified using\ntwo main literals namely '#' (Pound) and 'x'. '#' specifies that input should be passed on to output, 'x' would replace\nthe input charater with it. Any other characters will be passed as it to the output.\nThis directive is mainly used for masking SSN, customer id, credit card numbers, etc.\n\n**Specification**\n\n```\n  mask-number {column-name} {masking-pattern}\n```\n* column-name - Name of the column to which the masking pattern needs to be applied\n* masking-pattern - Defines the pattern to be used for masking the column.\n\n**Example**\n```\n  mask-number ssn xxx-xx-####\n  mask-number credircard xxxx-xxxxxx-x####\n```\n\nShuffle based masking allows one to replace the input with the same size random data. It replaces\nnumbers with random numbers and string of characters with random characters.\n\n**Specificagtion**\n```\n  mask-shuffle {column-name}\n```\n\n* column-name - Name of the column to be shuffle masked.\n\n**Example**\n```\n  mask-shuffle address\n```\n\n### Date Transformation\n\nDirective for transforming a date from one format to another, or for transforming from unix timetsamp to\na format of date.\n\nTo convert a date string from one format to another use the following directive.\n\n**Specification**\n```\n  format-date {column-name} {source-date-format} {destination-date-format}\n```\n* column-name - Name of the column to convert from source to destination format.\n* source-date-format - Specifies the format of date pattern.\n* destination-date-format - Specifies the format of date pattern.\n\n**Example**\n```\n  format-date date MM/dd/yyyy EEE, MMM d, ''yy\n```\n\nTo convert from unix timestamp to a date format use the following directive\n**Specificaton**\n\n```\n  format-unix-timestamp {column-name} {date-format}\n```\n* column-name - Name of the column that contains unix timestamp that needs to be converted to date-format\n* date-format - Format to convert from unix timestamp.\n\n**Example**\n```\n  format-unix-timestamp timestamp MM/dd/yyyy\n```"
  }
}