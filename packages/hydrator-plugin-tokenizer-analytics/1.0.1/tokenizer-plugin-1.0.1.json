{
  "parents": [
    "system:cdap-etl-batch[4.1.0,5.1.0-SNAPSHOT)",
    "system:cdap-data-pipeline[4.1.0,5.1.0-SNAPSHOT)",
    "system:cdap-data-streams[4.1.0,5.1.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.Tokenizer-sparkcompute": "{\"metadata\":{\"spec-version\":\"1.0\"},\"configuration-groups\":[{\"label\":\"Tokenizer Properties\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Column To Be Tokenized\",\"name\":\"columnToBeTokenized\"},{\"widget-type\":\"textbox\",\"label\":\"Pattern Separator\",\"name\":\"patternSeparator\"},{\"widget-type\":\"textbox\",\"label\":\"Output Column Name\",\"name\":\"outputColumn\"}]}],\"outputs\":[]}",
    "doc.Tokenizer-sparkcompute": "# Tokenizer Spark Compute\n\nDescription\n-----------\nTokenization is the process of taking text (such as a sentence) and breaking it into individual terms (usually words) \non the basis of pattern.\n\nTokenizer splits data on the basis of specified pattern and emits the output as string array of tokens.\n\nUse Case\n--------\nUser wants to extract the hashtags from the twitter feeds. User would tokenize the words based on space and then can\nidentify the words that start with hashtags.\n\nProperties\n----------\n**columnToBeTokenized:** Column on which tokenization is to be done.\n\n**patternSeparator:** Pattern separator for tokenization.\n\n**outputColumn:** Output column name for tokenized data.\n\nExample\n-------\nThis example tokenizes \"sentence\" column into output column \"words\" using pattern \"/\".\n\n    {\n        \"name\": \"Tokenizer\",\n        \"type\": \"sparkcompute\",\n        \"properties\": {\n            \"columnToBeTokenized\": \"sentence\",\n            \"patternSeparator\": \"/\",\n            \"outputColumn\": \"words\"\n        }\n    }\n\n\nFor example, suppose the tokenizer receives below input records:\n\n    +=======================================================+\n    | topic | sentence                                      |\n    +=======================================================+\n    | java  | Hello world / is the /basic application       |\n    | HDFS  | HDFS/ is a /file system                       |\n    | Spark | Spark /is an engine for /bigdata processing   |\n    +=======================================================+\n\nOutput schema will contain additional column \"words\" having tokenized data in string array form:\n\n    +=====================================================================================================+\n    | topic | sentence                                     | words                                        |\n    +=====================================================================================================+\n    | java  | Hello world / is the /basic application      | [Hello world , is the ,basic application]    |\n    | HDFS  | HDFS/ is a /file system                      | [Hdfs, is a ,file system]                    |\n    | Spark | Spark /is an engine for /bigdata processing  | [Spark ,is an engine for ,bigdata processing]|\n    +=====================================================================================================+\n"
  }
}