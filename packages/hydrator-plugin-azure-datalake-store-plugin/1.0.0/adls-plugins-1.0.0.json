{
  "parents": [
    "system:cdap-data-pipeline[4.2.0-SNAPSHOT,4.3.0-SNAPSHOT)",
    "system:cdap-data-streams[4.2.0-SNAPSHOT,4.3.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.AzureDataLakeStore-batchsource": "{\"metadata\":{\"spec-version\":\"1.0\"},\"configuration-groups\":[{\"label\":\"Azure Data Lake Store Configuration\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Reference Name\",\"name\":\"referenceName\"},{\"widget-type\":\"textbox\",\"label\":\"Azure Data Lake Store Path\",\"name\":\"path\"},{\"widget-type\":\"textbox\",\"label\":\"Azure Data Lake Store Client Id\",\"name\":\"clientId\"},{\"widget-type\":\"textbox\",\"label\":\"Azure Data Lake Store Refresh Token\",\"name\":\"refreshTokenURL\"},{\"widget-type\":\"textbox\",\"label\":\"Azure Data Lake Store Credentials\",\"name\":\"credentials\"},{\"widget-type\":\"textbox\",\"label\":\"Maximum Split Size\",\"name\":\"maxSplitSize\"},{\"widget-type\":\"textbox\",\"label\":\"Regex Path Filter\",\"name\":\"fileRegex\"},{\"widget-type\":\"select\",\"label\":\"Read files recursively\",\"name\":\"recursive\",\"widget-attributes\":{\"values\":[\"true\",\"false\"],\"default\":\"false\"}},{\"label\":\"Output Schema Properties\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Path Field\",\"name\":\"pathField\",\"plugin-function\":{\"method\":\"POST\",\"widget\":\"outputSchema\",\"output-property\":\"schema\",\"plugin-method\":\"getSchema\"}},{\"widget-type\":\"select\",\"label\":\"Use File Name as Path Field\",\"name\":\"filenameOnly\",\"widget-attributes\":{\"values\":[\"true\",\"false\"],\"default\":\"false\"}}]},{\"label\":\"Advanced Properties\",\"properties\":[{\"widget-type\":\"textbox\",\"label\":\"Input Format Class\",\"name\":\"inputFormatClass\"},{\"widget-type\":\"json-editor\",\"label\":\"File System Properties\",\"name\":\"fileSystemProperties\"},{\"widget-type\":\"select\",\"label\":\"Ignore Non-Existing Folders\",\"name\":\"ignoreNonExistingFolders\",\"widget-attributes\":{\"values\":[\"true\",\"false\"],\"default\":\"false\"}},{\"widget-type\":\"textbox\",\"label\":\"Time Table\",\"name\":\"timeTable\"}]}]}],\"outputs\":[{\"name\":\"schema\",\"widget-type\":\"schema\",\"widget-attributes\":{\"default-schema\":{\"name\":\"fileRecord\",\"type\":\"record\",\"fields\":[{\"name\":\"offset\",\"type\":\"long\"},{\"name\":\"body\",\"type\":\"string\"}]}}}]}",
    "doc.AzureDataLakeStore-batchsource": "# Azure Data Lake Store Batch Source\n\nDescription\n-----------\nAzure Data Lake Store Batch Source reads data from Azure Data Lake Store files and converts it into \nStructuredRecord.\n\nProperties\n----------\n**referenceName:** This will be used to uniquely identify this source for lineage, annotating metadata, etc.\n\n**path** Path files under to Azure Data Lake Store directory\n\n**clientId** Microsoft Azure client Id which is typically Application Id\n \n**refreshTokenURL** Refresh URL to access Microsoft Azure Data Store \n\n**credentials** Key to access Microsoft Azure Data Store\n\n**maxSplitSize:** Maximum split-size for each mapper in the MapReduce Job. Defaults to 128MB. (Macro-enabled)\n\n**fileRegex:** Regex to filter out filenames in the path.\nTo use the *TimeFilter*, input ``timefilter``. The TimeFilter assumes that it is\nreading in files with the File log naming convention of *YYYY-MM-DD-HH-mm-SS-Tag*.\nThe TimeFilter reads in files from the previous hour if the field ``timeTable`` is\nleft blank. If it's currently *2015-06-16-15* (June 16th 2015, 3pm), it will read\nin files that contain *2015-06-16-14* in the filename. If the field ``timeTable`` is\npresent, then it will read in files that have not yet been read. (Macro-enabled)\n\n**recursive** Boolean value to determine if files are to be read recursively from the path. Default is false.\n\n**inputFormatClass:** Name of the input format class, which must be a\nsubclass of FileInputFormat. Defaults to CombineTextInputFormat. (Macro-enabled)\n\n**ignoreNonExistingFolders:** Identify if path needs to be ignored or not, for case when directory or file does not\nexists. If set to true it will treat the not present folder as 0 input and log a warning. Default is false.\n\n**timeTable:** Name of the Table that keeps track of the last time files\nwere read in. (Macro-enabled)\n\n**pathField:** If specified, each output record will include a field with this name that contains the file URI\nthat the record was read from. Requires a customized version of CombineFileInputFormat, so it cannot be used\nif an inputFormatClass is given.\n\n**filenameOnly** If true and a pathField is specified, only the filename will be used. If false, the full \nURI will be used. Defaults to false.\n\n**fileSystemProperties:** A JSON string representing a map of properties\nneeded for the distributed file system. (Macro-enabled)\n\n\nExample\n-------\nThis example connects to Microsoft Azure Data Lake Store and reads in files found in the\nspecified directory. This example uses Microsoft Azure Data Lake Store 'xyz.azuredatalakestore.net', using the\n'clientID', oauth2 refreshTokenURL and Keys as Credentials :\n\n    {\n        \"name\": \"AzureBlobStore\",\n        \"type\": \"batchsource\",\n        \"properties\": {\n            \"schema\": \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"etlSchemaBody\\\",\\\"fields\\\":[{\\\"name\\\":\\\"offset\\\",\\\"type\\\":\\\"long\\\"},{\\\"name\\\":\\\"body\\\",\\\"type\\\":\\\"string\\\"}]}\",\n            \"recursive\": \"false\",\n            \"referenceName\": \"store\",\n            \"path\": \"adl://xyz.azuredatalakestore.net/adls\",\n            \"clientId\": \"2016c0cb-9b0a-411d-9976-457112a6baca\",\n            \"refreshTokenURL\": \"https://login.windows.net/6f3d9678-d0b4-4d7e-ac55-128e30605fac/oauth2/token\",\n            \"credentials\": \"d1cF7CwFJKlMWXPz30OZ0XD8DErPsSWf0zXyH4iDzKA=\"\n        }\n    }\n"
  }
}